{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "74b02435",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- SLP Results ---\n",
      "AND Gate: [0, 0, 0, 1]\n",
      "OR Gate: [0, 1, 1, 1]\n",
      "NAND Gate: [1, 1, 1, 0]\n",
      "NOR Gate: [1, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "class Perceptron:\n",
    "    def __init__(self, weights, bias):\n",
    "        self.weights = weights\n",
    "        self.bias = bias\n",
    "\n",
    "    def predict(self, x):\n",
    "        z = sum(w * i for w, i in zip(self.weights, x)) + self.bias\n",
    "        return 1 if z >= 0 else 0\n",
    "\n",
    "# Hardcoded weights for demonstration (could also be trained)\n",
    "gates_slp = {\n",
    "    \"AND\":  {\"w\": [1, 1], \"b\": -1.5},\n",
    "    \"OR\":   {\"w\": [1, 1], \"b\": -0.5},\n",
    "    \"NAND\": {\"w\": [-1, -1], \"b\": 1.5},\n",
    "    \"NOR\":  {\"w\": [-1, -1], \"b\": 0.5}\n",
    "}\n",
    "\n",
    "inputs = [[0, 0], [0, 1], [1, 0], [1, 1]]\n",
    "\n",
    "print(\"--- SLP Results ---\")\n",
    "for name, params in gates_slp.items():\n",
    "    p = Perceptron(params[\"w\"], params[\"b\"])\n",
    "    print(f\"{name} Gate: {[p.predict(i) for i in inputs]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a87a5b7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- MLP Results ---\n",
      "XOR Final Error: 0.00030\n",
      "XOR Predictions: [0, 1, 1, 0]\n",
      "XNOR Final Error: 0.00028\n",
      "XNOR Predictions: [1, 0, 0, 1]\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "class MLP:\n",
    "    def __init__(self):\n",
    "        # 2 inputs -> 2 hidden neurons -> 1 output\n",
    "        self.w_hidden = [[random.uniform(-1, 1) for _ in range(2)] for _ in range(2)]\n",
    "        self.b_hidden = [random.uniform(-1, 1) for _ in range(2)]\n",
    "        self.w_out = [random.uniform(-1, 1) for _ in range(2)]\n",
    "        self.b_out = random.uniform(-1, 1)\n",
    "        self.lr = 0.5\n",
    "\n",
    "    def sigmoid(self, x):\n",
    "        return 1 / (1 + math.exp(-x))\n",
    "\n",
    "    def sigmoid_derivative(self, x):\n",
    "        return x * (1 - x)\n",
    "\n",
    "    def train(self, inputs, targets, epochs=10000):\n",
    "        for _ in range(epochs):\n",
    "            total_error = 0\n",
    "            for x, y in zip(inputs, targets):\n",
    "                # Forward Pass\n",
    "                h_act = [self.sigmoid(sum(x[i]*self.w_hidden[j][i] for i in range(2)) + self.b_hidden[j]) for j in range(2)]\n",
    "                out = self.sigmoid(sum(h_act[i]*self.w_out[i] for i in range(2)) + self.b_out)\n",
    "                \n",
    "                error = y - out\n",
    "                total_error += error**2\n",
    "\n",
    "                # Backpropagation\n",
    "                d_out = error * self.sigmoid_derivative(out)\n",
    "                d_hidden = [d_out * self.w_out[i] * self.sigmoid_derivative(h_act[i]) for i in range(2)]\n",
    "\n",
    "                # Update Weights\n",
    "                for i in range(2):\n",
    "                    self.w_out[i] += self.lr * d_out * h_act[i]\n",
    "                self.b_out += self.lr * d_out\n",
    "\n",
    "                for j in range(2):\n",
    "                    for i in range(2):\n",
    "                        self.w_hidden[j][i] += self.lr * d_hidden[j] * x[i]\n",
    "                    self.b_hidden[j] += self.lr * d_hidden[j]\n",
    "        return total_error / len(inputs)\n",
    "\n",
    "    def predict(self, x):\n",
    "        h_act = [self.sigmoid(sum(x[i]*self.w_hidden[j][i] for i in range(2)) + self.b_hidden[j]) for j in range(2)]\n",
    "        return self.sigmoid(sum(h_act[i]*self.w_out[i] for i in range(2)) + self.b_out)\n",
    "\n",
    "# Training Data\n",
    "xor_targets = [0, 1, 1, 0]\n",
    "xnor_targets = [1, 0, 0, 1]\n",
    "\n",
    "mlp_xor = MLP()\n",
    "err_xor = mlp_xor.train(inputs, xor_targets)\n",
    "\n",
    "mlp_xnor = MLP()\n",
    "err_xnor = mlp_xnor.train(inputs, xnor_targets)\n",
    "\n",
    "print(\"\\n--- MLP Results ---\")\n",
    "print(f\"XOR Final Error: {err_xor:.5f}\")\n",
    "print(f\"XOR Predictions: {[round(mlp_xor.predict(i)) for i in inputs]}\")\n",
    "print(f\"XNOR Final Error: {err_xnor:.5f}\")\n",
    "print(f\"XNOR Predictions: {[round(mlp_xnor.predict(i)) for i in inputs]}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
